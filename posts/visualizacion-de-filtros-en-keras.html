<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href=../assets/style.css>

        <!-- Mathjax -->
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <!-- -->

        <link href="https://fonts.googleapis.com/css?family=Nunito+Sans|Nunito:300,400,700&display=swap" rel="stylesheet">
        <style>pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #232629;
    color: #7a7c7d;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
div.sourceCode
  { color: #cfcfc2; background-color: #232629; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #cfcfc2; } /* Normal */
code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
code span.an { color: #3f8058; } /* Annotation */
code span.at { color: #2980b9; } /* Attribute */
code span.bn { color: #f67400; } /* BaseN */
code span.bu { color: #7f8c8d; } /* BuiltIn */
code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #3daee9; } /* Char */
code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
code span.co { color: #7a7c7d; } /* Comment */
code span.cv { color: #7f8c8d; } /* CommentVar */
code span.do { color: #a43340; } /* Documentation */
code span.dt { color: #2980b9; } /* DataType */
code span.dv { color: #f67400; } /* DecVal */
code span.er { color: #da4453; text-decoration: underline; } /* Error */
code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
code span.fl { color: #f67400; } /* Float */
code span.fu { color: #8e44ad; } /* Function */
code span.im { color: #27ae60; } /* Import */
code span.in { color: #c45b00; } /* Information */
code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
code span.op { color: #cfcfc2; } /* Operator */
code span.ot { color: #27ae60; } /* Other */
code span.pp { color: #27ae60; } /* Preprocessor */
code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #da4453; } /* SpecialString */
code span.st { color: #f44f4f; } /* String */
code span.va { color: #27aeae; } /* Variable */
code span.vs { color: #da4453; } /* VerbatimString */
code span.wa { color: #da4453; } /* Warning */</style>

                <meta name="description" content="Exploraremos lo que aprende una red neuronal a partir de una visualización de sus filtros.">
                <meta>
                <meta name="author" content="Alberto Di Biase">
                        <meta name="dcterms.date" content="">
                <title>Visualización de filtros de redes neuronales en Keras - Alberto Di Biase</title>


    </head>

    <body>
        <!-- Header -->
        <header>
            <h1 class="site-title">
                <a href=https://tito21.github.io/index.html>Alberto Di Biase</a>
            </h1>
            <nav>
                <ul class="nav-list">
                                            <li><a href=https://tito21.github.io/about.html>About</a></li>
                                            <li><a href=https://tito21.github.io/categories.html>Categories</a></li>
                                    </ul>
            </nav>
        </header>
        <article class="main-article">
            <h1 class="article-title">Visualización de filtros de redes neuronales en Keras</h1>
            <div class="sub-title">
                                    <span>2019-02-18 22:22:43 -0300</span>
                                <ul>
                                            <li><a href=https://tito21.github.io/categories.html#Python>Python</a></li>
                                            <li><a href=https://tito21.github.io/categories.html#redes neuronales>redes neuronales</a></li>
                                            <li><a href=https://tito21.github.io/categories.html#programacion>programacion</a></li>
                                            <li><a href=https://tito21.github.io/categories.html#visualizacion>visualizacion</a></li>
                                            <li><a href=https://tito21.github.io/categories.html#tutorial>tutorial</a></li>
                                    </ul>
            </div>

<h1 id="qué-aprenden-las-redes-neuronales">¿Qué aprenden las redes neuronales?</h1>
<p>Durante el ultimo año he esta aprendiendo sobre aprendizaje de maquina (ML) específicamente en redes neuronales convencionales (CNN) aplicado a imágenes de resonancia magnética (MRI). En este articulo voy a explorar como las CNN interpretan las imágenes que le damos de entrada y como las activaciones se propagan por las diferentes capas de la red. Este articulo esta basado en este <a href="https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html">post</a> por Francois Chollet creador de Keras.</p>
<p>Las CNNs aprenden una serie de filtros que aplican a las imágenes de entrada para lograr un objetivo (ej clasificación, reconstrucción, etc) Para poder interpretar como la red interpreta las imágenes es útil visualizar los filtros. Nuestro objetivo sera buscar una imagen que maximice el activación de una de uno de los filtros en las capas convulucionales de la red. Esta técnica es útil para corroborar que la red halla aprendido características pertinentes para resolver el problema. Ademas es la técnica que se utiliza para generar las imágenes de <a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">Deep Dream</a></p>
<h2 id="cargando-la-red">Cargando la red</h2>
<p>Vamos a usar un red U-net propuesta en el 2015 <a href="https://arxiv.org/abs/1505.04597">[1]</a> para la segmentación de imágenes biomédica. En esta red consta de dos partes, una primera compresora las imágenes reduciendo sus dimensiones y luego parte decodificadora que aumenta el tamaño de la imagen recuperando la imagen original. La innovación en esta red esta en que tiene conexiones que conectan alternadamente las dos partes de la red facilitando el flujo de información a través de ella.</p>
<p>Durante el mes pasado la utilice para mejora la reconstrucción de imágenes de resonancia magnética. Básicamente esta red toma una imagen <em>undersample</em> en el espacio de la frecuencia y la reconstruye para que no se noten los artefactos del <a href="https://es.wikipedia.org/wiki/Aliasing"><em>aliasing</em></a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Esta red yo ya la configure y entrene usando imágenes simuladas (vivan los círculos y rectángulos). La red completa, junto sus pesos esta disponible <a href="https://drive.google.com/file/d/1v4uk8s5aU09g-iIidWJ97QbO2Uk2p1H8/view?usp=sharing">aquí</a>. Algunas imágenes del set de entrenamiento, la reconstrucción mejorada y su version con <em>aliasing</em>.</p>
<p><img src="/assets/posts/visualizacion-filtros-keras/ej1.png" alt="Ejemplo de entrada, salida y valor verdadero de la red" /> <img src="/assets/posts/visualizacion-filtros-keras/ej2.png" alt="Ejemplo de entrada, salida y valor verdadero de la red" /> <img src="/assets/posts/visualizacion-filtros-keras/ej3.png" alt="Ejemplo de entrada, salida y valor verdadero de la red" /> <img src="/assets/posts/visualizacion-filtros-keras/ej4.png" alt="Ejemplo de entrada, salida y valor verdadero de la red" /></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> keras.models <span class="im">import</span> load_model</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> keras.utils <span class="im">import</span> get_file</span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a>modelpath <span class="op">=</span> get_file(<span class="st">&quot;/content/model.h5&quot;</span>, <span class="st">&quot;https://drive.google.com/a/uc.cl/uc?export=download&amp;id=1v4uk8s5aU09g-iIidWJ97QbO2Uk2p1H8&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="bu">print</span>(modelpath)</span>
<span id="cb1-6"><a href="#cb1-6"></a>model <span class="op">=</span> load_model(modelpath)</span>
<span id="cb1-7"><a href="#cb1-7"></a>model.summary()</span></code></pre></div>
<pre><code>Using TensorFlow backend.


Downloading data from https://drive.google.com/a/uc.cl/uc?export=download&amp;id=1v4uk8s5aU09g-iIidWJ97QbO2Uk2p1H8
34684928/Unknown - 7s 0us/step/content/model.h5
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 128, 128, 1)  0
__________________________________________________________________________________________________
dconv64 (Conv2D)                (None, 128, 128, 64) 640         input_3[0][0]
__________________________________________________________________________________________________
conv64_1 (BatchNormalization)   (None, 128, 128, 64) 256         dconv64[0][0]
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 64)   0           conv64_1[0][0]
__________________________________________________________________________________________________
dconv128 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_5[0][0]
__________________________________________________________________________________________________
conv128_1 (BatchNormalization)  (None, 64, 64, 128)  512         dconv128[0][0]
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 128)  0           conv128_1[0][0]
__________________________________________________________________________________________________
dconv256 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_6[0][0]
__________________________________________________________________________________________________
conv256_1 (BatchNormalization)  (None, 32, 32, 256)  1024        dconv256[0][0]
__________________________________________________________________________________________________
code (MaxPooling2D)             (None, 16, 16, 256)  0           conv256_1[0][0]
__________________________________________________________________________________________________
conv512 (Conv2D)                (None, 16, 16, 512)  1180160     code[0][0]
__________________________________________________________________________________________________
up_sampling2d_7 (UpSampling2D)  (None, 32, 32, 512)  0           conv512[0][0]
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 32, 32, 768)  0           up_sampling2d_7[0][0]
                                                                 conv256_1[0][0]
__________________________________________________________________________________________________
uconv256 (Conv2D)               (None, 32, 32, 128)  884864      concatenate_7[0][0]
__________________________________________________________________________________________________
conv512_2 (BatchNormalization)  (None, 32, 32, 128)  512         uconv256[0][0]
__________________________________________________________________________________________________
up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 128)  0           conv512_2[0][0]
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 64, 64, 256)  0           up_sampling2d_8[0][0]
                                                                 conv128_1[0][0]
__________________________________________________________________________________________________
uconv128 (Conv2D)               (None, 64, 64, 128)  295040      concatenate_8[0][0]
__________________________________________________________________________________________________
conv128_2 (BatchNormalization)  (None, 64, 64, 128)  512         uconv128[0][0]
__________________________________________________________________________________________________
up_sampling2d_9 (UpSampling2D)  (None, 128, 128, 128 0           conv128_2[0][0]
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_9[0][0]
                                                                 conv64_1[0][0]
__________________________________________________________________________________________________
uconv64 (Conv2D)                (None, 128, 128, 64) 110656      concatenate_9[0][0]
__________________________________________________________________________________________________
conv64_2 (BatchNormalization)   (None, 128, 128, 64) 256         uconv64[0][0]
__________________________________________________________________________________________________
econv64 (Conv2D)                (None, 128, 128, 64) 36928       conv64_2[0][0]
__________________________________________________________________________________________________
conv64_3 (BatchNormalization)   (None, 128, 128, 64) 256         econv64[0][0]
__________________________________________________________________________________________________
final_conv1 (Conv2D)            (None, 128, 128, 1)  577         conv64_3[0][0]
==================================================================================================
Total params: 2,881,217
Trainable params: 2,879,553
Non-trainable params: 1,664
__________________________________________________________________________________________________</code></pre>
<p>Ya cargado el modelo, definimos una función que maximice uno de los filtros de la entrada</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> keras <span class="im">import</span> backend <span class="im">as</span> K</span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># definir un diccionario con el nombre de cada capa</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>layer_dict <span class="op">=</span> <span class="bu">dict</span>([(layer.name, layer) <span class="cf">for</span> layer <span class="kw">in</span> model.layers])</span>
<span id="cb3-5"><a href="#cb3-5"></a>input_img <span class="op">=</span> model.inputs[<span class="dv">0</span>]</span>
<span id="cb3-6"><a href="#cb3-6"></a>layer_name <span class="op">=</span> <span class="st">&#39;dconv64&#39;</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>filter_index <span class="op">=</span> <span class="dv">0</span> <span class="co"># cualquiera de los 64 filtros en esa capa</span></span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a>layer_output <span class="op">=</span> layer_dict[layer_name].output</span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co"># Una funcion de costo que maximiza la activacion del filtro</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>loss <span class="op">=</span> K.mean(layer_output[:, :, :, filter_index])</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-14"><a href="#cb3-14"></a>grads <span class="op">=</span> K.gradients(loss, input_img)[<span class="dv">0</span>]</span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co"># es importante normalizar los gradientes</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>grads <span class="op">/=</span> (K.sqrt(K.mean(K.square(grads))) <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"># una funcion para calcular la los gradientes dada una imagen de entrada</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>iterate <span class="op">=</span> K.function([input_img], [loss, grads])</span></code></pre></div>
<p>Usando la función de Keras que definimos podemos subir en el gradiente buscando la imagen que maximice el filtro. Esto puede tomar unos cuantos segundos.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a>SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>input_img_data <span class="op">=</span> np.random.random((<span class="dv">1</span>, <span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>))</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a><span class="co"># iteramos</span></span>
<span id="cb4-8"><a href="#cb4-8"></a>step <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb4-10"><a href="#cb4-10"></a>    loss_value, grads_value <span class="op">=</span> iterate([input_img_data])</span>
<span id="cb4-11"><a href="#cb4-11"></a>    input_img_data <span class="op">+=</span> grads_value <span class="op">*</span> step</span>
<span id="cb4-12"><a href="#cb4-12"></a></span>
<span id="cb4-13"><a href="#cb4-13"></a>plt.imshow(input_img_data[<span class="dv">0</span>, ..., <span class="dv">0</span>])</span>
<span id="cb4-14"><a href="#cb4-14"></a>plt.colorbar()</span>
<span id="cb4-15"><a href="#cb4-15"></a>plt.grid()</span>
<span id="cb4-16"><a href="#cb4-16"></a>plt.show()</span></code></pre></div>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_6_0.png" alt="" /><figcaption>png</figcaption>
</figure>
<p>Esta es la imagen que maximiza la activación del primer filtro de la primera convulucional de la red.</p>
<h2 id="listo">Listo</h2>
<p>Ahora podemos generalizar un poco el código y calcular la maxima activación para algunos de los filtros en cada capa.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">def</span> visual(input_imag, layer_name, filter_index):</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>    layer_output <span class="op">=</span> layer_dict[layer_name].output</span>
<span id="cb5-4"><a href="#cb5-4"></a>    loss <span class="op">=</span> K.mean(layer_output[:, :, :, filter_index])</span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a>    grads <span class="op">=</span> K.gradients(loss, input_img)[<span class="dv">0</span>]</span>
<span id="cb5-7"><a href="#cb5-7"></a>    grads <span class="op">/=</span> (K.sqrt(K.mean(K.square(grads))) <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb5-8"><a href="#cb5-8"></a>    iterate <span class="op">=</span> K.function([input_img], [loss, grads])</span>
<span id="cb5-9"><a href="#cb5-9"></a></span>
<span id="cb5-10"><a href="#cb5-10"></a>    input_img_data <span class="op">=</span> np.random.random((<span class="dv">1</span>, <span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>)) <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb5-11"><a href="#cb5-11"></a></span>
<span id="cb5-12"><a href="#cb5-12"></a>    <span class="co"># iteramos</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>    step <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb5-15"><a href="#cb5-15"></a>        loss_value, grads_value <span class="op">=</span> iterate([input_img_data])</span>
<span id="cb5-16"><a href="#cb5-16"></a>        input_img_data <span class="op">+=</span> grads_value <span class="op">*</span> step</span>
<span id="cb5-17"><a href="#cb5-17"></a></span>
<span id="cb5-18"><a href="#cb5-18"></a>    <span class="cf">return</span> input_img_data[<span class="dv">0</span>, ..., <span class="dv">0</span>]</span>
<span id="cb5-19"><a href="#cb5-19"></a></span>
<span id="cb5-20"><a href="#cb5-20"></a>layers <span class="op">=</span> [(<span class="st">&#39;dconv64&#39;</span>, <span class="dv">64</span>), (<span class="st">&#39;dconv128&#39;</span>, <span class="dv">128</span>), (<span class="st">&#39;dconv256&#39;</span>, <span class="dv">256</span>), (<span class="st">&#39;conv512&#39;</span>, <span class="dv">512</span>), (<span class="st">&#39;uconv256&#39;</span>, <span class="dv">128</span>), (<span class="st">&#39;uconv128&#39;</span>, <span class="dv">128</span>), (<span class="st">&#39;uconv64&#39;</span>, <span class="dv">64</span>)]</span>
<span id="cb5-21"><a href="#cb5-21"></a></span>
<span id="cb5-22"><a href="#cb5-22"></a>input_img <span class="op">=</span> model.inputs[<span class="dv">0</span>]</span>
<span id="cb5-23"><a href="#cb5-23"></a><span class="cf">for</span> name, filt <span class="kw">in</span> layers:</span>
<span id="cb5-24"><a href="#cb5-24"></a>  fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">8</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">3.5</span>))</span>
<span id="cb5-25"><a href="#cb5-25"></a>  ax <span class="op">=</span> ax.ravel()</span>
<span id="cb5-26"><a href="#cb5-26"></a>  fig.suptitle(name)</span>
<span id="cb5-27"><a href="#cb5-27"></a>  <span class="cf">for</span> a <span class="kw">in</span> ax:</span>
<span id="cb5-28"><a href="#cb5-28"></a>    i <span class="op">=</span> np.random.randint(<span class="dv">0</span>, filt)</span>
<span id="cb5-29"><a href="#cb5-29"></a>    a.imshow(visual(input_img, name, i))</span>
<span id="cb5-30"><a href="#cb5-30"></a>    a.set_xticks([])</span>
<span id="cb5-31"><a href="#cb5-31"></a>    a.set_yticks([])</span>
<span id="cb5-32"><a href="#cb5-32"></a></span>
<span id="cb5-33"><a href="#cb5-33"></a>  fig.tight_layout(pad<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb5-34"><a href="#cb5-34"></a>  fig.show()</span></code></pre></div>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_0.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_1.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_2.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_3.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_4.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_5.png" alt="" /><figcaption>png</figcaption>
</figure>
<figure>
<img src="/assets/posts/visualizacion-filtros-keras/output_8_6.png" alt="" /><figcaption>png</figcaption>
</figure>
<p>La mayoría de los filtros son selectores de lineas verticales y horizontales, lo que tiene sentido dada la forma del <em>aleasing</em>. En las capas superiores las lineas se comienzan a separar más indicando que la detección esta a un nivel mas global. Luego en las capas de <em>decoding</em> las activaciones se vuelven con una textura casi constante lo que refleja que se esta tratando de reconstruir la imagen. Otra observación importante es lo que hay varios filtros dedicadas a manejar los bordes.</p>
<p>Ademas, existen varias capas que pareciera que detectan solo ruido por lo que probablemente se podrían reducir la cantidad de filtros y mantener la calidad de los resultados.</p>
<p>Es sorprendente lo poco que entendemos de como aprenden las redes neuronales. Poder visualizar los filtros de nos abre una puerta para poder evaluar lo que realmente aprende nuestra red. Pero es aun un area en donde hay mucho que investigar.</p>
<h2 id="deepdream">DeepDream</h2>
<p>Una de las aplicaciones interesante de esta tecnología es la creación de imágenes que parecen de un sueño. En lugar de partir con ruido si se parte de fotografiás y maximizando la activación de un filtro la imagen generada parece venir de un sueño.</p>
<p>Si se activa uno de los primeros filtros comienzan a aparecer patrones simples como lineas o círculos. Pero si se activan alguna de las capas más profundas comienzan a aparecer patrones más complejos que asemejan las clases con las que fue entrenada la red. Imágenes de Google AI Blog 2015.</p>
<figure>
<img src="https://4.bp.blogspot.com/-PK_bEYY91cw/VYIVBYw63uI/AAAAAAAAAlo/iUsA4leua10/s640/seurat-layout.png" alt="" /><figcaption>Left: Original painting by Georges Seurat. Right: processed images by Matthew McNaughton, Software Engineer</figcaption>
</figure>
<figure>
<img src="https://4.bp.blogspot.com/-FPDgxlc-WPU/VYIV1bK50HI/AAAAAAAAAlw/YIwOPjoulcs/s640/skyarrow.png" alt="" /><figcaption>Nubes</figcaption>
</figure>
<p>Puedes <a href="/assets/posts/visualizacion-filtros-keras/notebook.ipynb">descargar</a> este articulo como un cuaderno Jupyter. El código del post original de Keras esta disponible en <a href="https://github.com/keras-team/keras/blob/master/examples/conv_filter_visualization.py">GitHub</a></p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>La adquisición de imágenes de MR se realiza en el dominio de la frecuencia o <a href="https://en.wikipedia.org/wiki/K-space_(magnetic_resonance_imaging)">espacio <em>k</em></a>. Una forma de acelerar el tiempo requerido en la adquisición es saltar datos de frecuencia y por tanto violando el criterio de <a href="https://es.wikipedia.org/wiki/Teorema_de_muestreo_de_Nyquist-Shannon">Nyquist</a>, lo que genera la aparición de replicas o <em>aliasing</em>. <a href="https://mriquestions.com/compressed-sensing.html">Aqui</a> puedes leer mas sobre el tema.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        </article>

        <footer>
            <div class="footer-container">
                <div class="footer-colm">
                    <a href=https://tito21.github.io>Alberto Di Biase</a>
                    <ul>
                                                    <li><a href=about.html>About</a></li>
                                                    <li><a href=categories.html>Categories</a></li>
                                            </ul>
                </div>
                <div class="footer-colm">
                    Redes Sociales:
                    <ul>
                                                    <li><a href=https://github.com/tito21/>github</a></li>
                                                    <li><a href=https://www.reddit.com/user/AlbertoDiBiase>reddit</a></li>
                                            </ul>
                </div>
                <div class="footer-colm" style="text-align: left;">
                    <p>Estudiante de Ingeniería Biomédica en la Pontificia Universidad Católica de Chile (UC). Mis pasiones son programar, los numeros y la enseñanza.</p>
                </div>
            </div>
        </footer>
        <div class="close-message">
            <p>Todo el contenido de esta pagina esta bajo la Licencia <a
            href="http://creativecommons.org/licenses/by-sa/4.0/">CC-by-sa</a> y
            el código bajo la licencia <a
            href="https://choosealicense.com/licenses/mit/">MIT</a></p>

                <p>Sitio alojado en <a href="github.com">GitHub</a> y producido
                con YASSG</p>
        </div>
    </body>

</html>