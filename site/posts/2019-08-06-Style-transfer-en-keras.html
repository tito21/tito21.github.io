<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href=../assets/style.css>

        <!-- Mathjax -->
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <!-- -->

        <link href="https://fonts.googleapis.com/css?family=Nunito+Sans|Nunito:300,400,700&display=swap" rel="stylesheet">
        <style>pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #232629;
    color: #7a7c7d;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
div.sourceCode
  { color: #cfcfc2; background-color: #232629; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #cfcfc2; } /* Normal */
code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
code span.an { color: #3f8058; } /* Annotation */
code span.at { color: #2980b9; } /* Attribute */
code span.bn { color: #f67400; } /* BaseN */
code span.bu { color: #7f8c8d; } /* BuiltIn */
code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #3daee9; } /* Char */
code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
code span.co { color: #7a7c7d; } /* Comment */
code span.cv { color: #7f8c8d; } /* CommentVar */
code span.do { color: #a43340; } /* Documentation */
code span.dt { color: #2980b9; } /* DataType */
code span.dv { color: #f67400; } /* DecVal */
code span.er { color: #da4453; text-decoration: underline; } /* Error */
code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
code span.fl { color: #f67400; } /* Float */
code span.fu { color: #8e44ad; } /* Function */
code span.im { color: #27ae60; } /* Import */
code span.in { color: #c45b00; } /* Information */
code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
code span.op { color: #cfcfc2; } /* Operator */
code span.ot { color: #27ae60; } /* Other */
code span.pp { color: #27ae60; } /* Preprocessor */
code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #da4453; } /* SpecialString */
code span.st { color: #f44f4f; } /* String */
code span.va { color: #27aeae; } /* Variable */
code span.vs { color: #da4453; } /* VerbatimString */
code span.wa { color: #da4453; } /* Warning */</style>

                <meta name="description" content="Veremos como usar una red neuronal (CNN) para generar obras de arte a partir de una foto. Usaremos una pintura famosa para capturar el estilo del artista para plasmarlo en imagen cualquiera.">
                <meta>
                <meta name="author" content="Alberto Di Biase">
                        <meta name="dcterms.date" content="">
                <title>AI puede crear obras de arte - Style Transfer en Keras - Alberto Di Biase</title>


    </head>

    <body>
        <!-- Header -->
        <header>
            <h1 class="site-title">
                <a href=http://192.168.0.27:8000/index.html>Alberto Di Biase</a>
            </h1>
            <nav>
                <ul class="nav-list">
                                            <li><a href=http://192.168.0.27:8000/about.html>About</a></li>
                                            <li><a href=http://192.168.0.27:8000/categories.html>Categories</a></li>
                                    </ul>
            </nav>
        </header>
        <article class="main-article">
            <h1 class="article-title">AI puede crear obras de arte - Style Transfer en Keras</h1>
            <div class="sub-title">
                                    <span>2019-08-01 22:22:43 -0300</span>
                                <ul>
                                            <li><a href=http://192.168.0.27:8000/categories.html#Python>Python</a></li>
                                            <li><a href=http://192.168.0.27:8000/categories.html#redes neuronales>redes neuronales</a></li>
                                            <li><a href=http://192.168.0.27:8000/categories.html#programacion>programacion</a></li>
                                            <li><a href=http://192.168.0.27:8000/categories.html#visualizacion>visualizacion</a></li>
                                            <li><a href=http://192.168.0.27:8000/categories.html#tutorial>tutorial</a></li>
                                    </ul>
            </div>

<p>En un post <a href="2019-02-20-Visualizacion-de-filtros-de-redes-neuronales-en-keras.html">anterior</a> exploramos los filtros de una red convolucional (CNN) para entender como esta funcionaba. Esa ves buscamos una imagen que maximice la activacion en cada filtro y de esta forma veíamos las características que este estaba detectando. Al final del articulo mencionamos el trabajo realizado en Google para crear imágenes de ensueño conocido como DeepDream. Poco después de la publicación de DeepDream, Gatys <em>et al.</em> <a href="https://arxiv.org/abs/1508.06576">[1]</a> mostraron como aplicar la técnica para generar obras de arte a partir de una foto siguiendo el estilo de una obra.</p>
<figure>
<img src="/assets/posts/style-transfer/presentacion.jpg" alt="" /><figcaption>Style Transfer</figcaption>
</figure>
<h2 id="style-transfer">Style transfer</h2>
<p>Los autores plantearon el problema de transferir el estilo de una imagen a otra como un problema de optimización. Intuitivamente las características de una foto se pueden dividir entre el contenido y el estilo (o texturas). El contenido corresponde a la información sobre la forma y ubicación de los objetos de la foto. El estilo son las texturas y patrones de la imagen. Bajo esta perspectiva si generamos una imagen con el contenido de una foto pero con las texturas de una obra de arte podemos “traspasar” el estilo del artista a la foto.</p>
<p>Para extraer el contenido y estilo de las imágenes los autores plantean el uso de una red CNN pre entrenada (especificamente la red VGG19 entrenada en ImageNet). Las CNNs entrenadas para clasificar sobre un gran volumen de datos aprenden una gran cantidad de filtros con distintas características que permiten identificar los objetos presentes. En cada etapa de la red la cantidad de filtros aumenta y el tamaño de las imágenes se disminuyen produciendo una reducción en la cantidad de unidades por capa. La representación contenida en estos filtros se puede utilizar para reconstruir la imagen original (abajo en la figura) o para reconstruir construir un espacio que considere solo la textura y estilo de una imagen (arriba en la figura).</p>
<figure>
<img src="/assets/posts/style-transfer/diagrama-cnn.jpg" alt="" /><figcaption>Una red CNN descompone la imagen en una serie de filtros.</figcaption>
</figure>
<p>La imagen solución es una que minimize simultáneamente la diferencia en estilo con la obra de arte y el contenido con la fotografiá. Denotando <span class="math inline">\(x\)</span> la imagen objetivo, <span class="math inline">\(x_s\)</span> la foto original y <span class="math inline">\(a_t\)</span> la obra de arte, la función de perdida a minimizar es,</p>
<p><span class="math display">\[\min_x \mathcal{L}=\frac{1}{2}(C(x)-C(x_s))^2-\lambda\frac{1}{2}(S(x_s)-S(a_t))^2\]</span></p>
<p>La expresión <span class="math inline">\((C(x)-C(x_s))^2\)</span> es la diferencia en el contenido y el termino <span class="math inline">\((S(x_s)-S(a_t))^2\)</span> es la diferencia en estilo. El valor de <span class="math inline">\(\lambda\)</span> es una constante para indicar una preferencia por el estilo o el contenido en la solución.</p>
<h2 id="implementación-en-keras">Implementación en Keras</h2>
<p>Primero cargamos las imágenes y el modelo VGG19 pre entrenado directamente de Keras.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> keras.applications <span class="im">import</span> vgg19</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> requests</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a>model <span class="op">=</span> vgg19.VGG19(weights<span class="op">=</span><span class="st">&#39;imagenet&#39;</span>, include_top<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="bu">print</span>(<span class="st">&#39;Model loaded.&#39;</span>)</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co"># model.summary()</span></span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a>van_gogh_url <span class="op">=</span> <span class="st">&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/606px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg&quot;</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>santiago_url <span class="op">=</span> <span class="st">&quot;https://upload.wikimedia.org/wikipedia/commons/7/7e/Stog_skyline_wikipedai.jpg&quot;</span></span>
<span id="cb1-13"><a href="#cb1-13"></a></span>
<span id="cb1-14"><a href="#cb1-14"></a>van_gogh <span class="op">=</span> np.array(Image.<span class="bu">open</span>(requests.get(van_gogh_url, stream<span class="op">=</span><span class="va">True</span>).raw).convert(<span class="st">&quot;RGB&quot;</span>))</span>
<span id="cb1-15"><a href="#cb1-15"></a>santiago <span class="op">=</span> np.array(Image.<span class="bu">open</span>(requests.get(santiago_url, stream<span class="op">=</span><span class="va">True</span>).raw).convert(<span class="st">&quot;RGB&quot;</span>))</span></code></pre></div>
<p>El estilo de la obra de arte y el contenido de la foto no va a cambiar durante el entrenamiento asi que es conveniente calcularlo previamente y guardarlo en una variable. Para obtener el resultado de una capa intermedia usamos un modelo donde la salida sea esa capa y predecimos las imágenes en el.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Model</span>
<span id="cb2-2"><a href="#cb2-2"></a>photo <span class="op">=</span> vgg19.preprocess_input(np.array([santiago]))</span>
<span id="cb2-3"><a href="#cb2-3"></a>target <span class="op">=</span> vgg19.preprocess_input(np.array([van_gogh]))</span>
<span id="cb2-4"><a href="#cb2-4"></a>target_style <span class="op">=</span> []</span>
<span id="cb2-5"><a href="#cb2-5"></a></span>
<span id="cb2-6"><a href="#cb2-6"></a>target_content <span class="op">=</span> Model(inputs<span class="op">=</span>model.<span class="bu">input</span>, outputs<span class="op">=</span>model.get_layer(<span class="st">&quot;block1_conv1&quot;</span>).output).predict(photo)</span>
<span id="cb2-7"><a href="#cb2-7"></a></span>
<span id="cb2-8"><a href="#cb2-8"></a>target_style.append(Model(inputs<span class="op">=</span>model.<span class="bu">input</span>, outputs<span class="op">=</span>model.get_layer(<span class="st">&quot;block5_conv1&quot;</span>).output).predict(target))</span>
<span id="cb2-9"><a href="#cb2-9"></a>target_style.append(Model(inputs<span class="op">=</span>model.<span class="bu">input</span>, outputs<span class="op">=</span>model.get_layer(<span class="st">&quot;block4_conv1&quot;</span>).output).predict(target))</span>
<span id="cb2-10"><a href="#cb2-10"></a>target_style.append(Model(inputs<span class="op">=</span>model.<span class="bu">input</span>, outputs<span class="op">=</span>model.get_layer(<span class="st">&quot;block3_conv1&quot;</span>).output).predict(target))</span>
<span id="cb2-11"><a href="#cb2-11"></a>target_style.append(Model(inputs<span class="op">=</span>model.<span class="bu">input</span>, outputs<span class="op">=</span>model.get_layer(<span class="st">&quot;block2_conv1&quot;</span>).output).predict(target))</span></code></pre></div>
<p>Yo elegí estas capas porque parecen dar buenos resultados esta situacion pero deberias experimentar con otras combinaciones.</p>
<p>Ahora definimos una función de Keras para calcular la función de perdida y el gradiente respecto de la imagen generada. Primero calculamos la perdida respecto del contenido</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> keras <span class="im">import</span> backend <span class="im">as</span> K</span>
<span id="cb3-2"><a href="#cb3-2"></a>content <span class="op">=</span> model.get_layer(<span class="st">&quot;block1_conv1&quot;</span>).output</span>
<span id="cb3-3"><a href="#cb3-3"></a>content_loss <span class="op">=</span> <span class="fl">0.5</span><span class="op">*</span>K.<span class="bu">sum</span>(K.<span class="bu">pow</span>(content <span class="op">-</span> target_content, <span class="dv">2</span>))</span></code></pre></div>
<p>Para calcular el error respecto del estilo debemos eliminar las relaciones espaciales implícitas en los filtros. La solución propuesta por Gatys <em>et al.</em> <a href="https://arxiv.org/abs/1508.06576">[1]</a> es usar la <a href="https://es.wikipedia.org/wiki/Matriz_de_Gram">matriz de Gram</a>. Definida como la matriz formada por el producto punto entre todos los vectores pertenecientes al conjunto. La forma mas simple de implementarlo es como la multiplicación <span class="math inline">\(AA^T\)</span> para una matriz <span class="math inline">\(A\)</span> cuyas filas sean los vectores requeridos. Adicionalmente el estilo es escala por la cantidad de elementos en la imagen.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> gram_matrix(x):</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="co">#   print(x.shape)</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  x <span class="op">=</span> K.batch_flatten(K.permute_dimensions(x, (<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)))</span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span class="cf">return</span> K.dot(x, K.transpose(x))</span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a>style <span class="op">=</span> []</span>
<span id="cb4-7"><a href="#cb4-7"></a>style.append(model.get_layer(<span class="st">&quot;block5_conv1&quot;</span>).output)</span>
<span id="cb4-8"><a href="#cb4-8"></a>style.append(layer_dict[<span class="st">&quot;block4_conv1&quot;</span>].output)</span>
<span id="cb4-9"><a href="#cb4-9"></a>style.append(layer_dict[<span class="st">&quot;block3_conv1&quot;</span>].output)</span>
<span id="cb4-10"><a href="#cb4-10"></a>style.append(layer_dict[<span class="st">&quot;block2_conv1&quot;</span>].output)</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a><span class="kw">def</span> get_style_loss(x, y, w):</span>
<span id="cb4-13"><a href="#cb4-13"></a>  size <span class="op">=</span> x.shape[<span class="dv">1</span>] <span class="op">*</span> x.shape[<span class="dv">2</span>] <span class="op">*</span> y.shape[<span class="dv">1</span>] <span class="op">*</span> y.shape[<span class="dv">2</span>]</span>
<span id="cb4-14"><a href="#cb4-14"></a>  target_gram <span class="op">=</span> gram_matrix(y[<span class="dv">0</span>])</span>
<span id="cb4-15"><a href="#cb4-15"></a>  photo_gram <span class="op">=</span> gram_matrix(x[<span class="dv">0</span>])</span>
<span id="cb4-16"><a href="#cb4-16"></a>  loss <span class="op">=</span> <span class="fl">0.25</span><span class="op">*</span>K.<span class="bu">sum</span>(K.<span class="bu">pow</span>(target_gram <span class="op">-</span> photo_gram, <span class="dv">2</span>))</span>
<span id="cb4-17"><a href="#cb4-17"></a>  loss <span class="op">=</span> w<span class="op">*</span>loss <span class="op">/</span>(<span class="dv">3</span><span class="op">*</span><span class="dv">422</span><span class="op">*</span><span class="dv">750</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-18"><a href="#cb4-18"></a>  <span class="cf">return</span> loss</span>
<span id="cb4-19"><a href="#cb4-19"></a></span>
<span id="cb4-20"><a href="#cb4-20"></a>style_loss <span class="op">=</span> [get_style_loss(s, ts, <span class="dv">1</span>) <span class="cf">for</span> (s, ts) <span class="kw">in</span> <span class="bu">zip</span>(style, target_style)]</span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co"># cambiar a la version final</span></span>
<span id="cb4-22"><a href="#cb4-22"></a>lam <span class="op">=</span> <span class="fl">1e2</span></span>
<span id="cb4-23"><a href="#cb4-23"></a>loss <span class="op">=</span> content_loss</span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="cf">for</span> i, s, ts <span class="kw">in</span> <span class="bu">enumerate</span>(style_loss,  <span class="bu">zip</span>(style, target_style)]):</span>
<span id="cb4-25"><a href="#cb4-25"></a>  w <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(i<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb4-26"><a href="#cb4-26"></a>  style_loss <span class="op">=</span> get_style_loss(s, ts, w)</span>
<span id="cb4-27"><a href="#cb4-27"></a>  loss <span class="op">+=</span> lam<span class="op">*</span>style_loss</span></code></pre></div>
<p>Luego la perdida total queda</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>lam <span class="op">=</span> <span class="fl">1e2</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>loss <span class="op">=</span> content_loss <span class="op">+</span> lam<span class="op">*</span>style_loss</span></code></pre></div>
<p>Usando la misma técnica que en el articulo anterior, creamos una función para calcular la perdida y el gradiente</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>input_img <span class="op">=</span> model.inputs[<span class="dv">0</span>]</span>
<span id="cb6-2"><a href="#cb6-2"></a>grads <span class="op">=</span> K.gradients(loss, input_img)[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co"># es importante normalizar los gradientes</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>grads <span class="op">/=</span> (K.sqrt(K.mean(K.square(grads))) <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co"># una funcion para calcular la los gradientes dada una imagen de entrada</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>iterate <span class="op">=</span> K.function([input_img], [loss, grads])</span></code></pre></div>
<p>Ya estamos llegando al final. Lo único que falta es iterar sobre la rutina que acabamos de definir actualizando la imagen en cada paso partiendo de ruido blanco.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">def</span> deprocess_image(x):</span>
<span id="cb7-2"><a href="#cb7-2"></a>  <span class="co"># sumar la media para volver al rango original</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  mean <span class="op">=</span> [<span class="fl">103.939</span>, <span class="fl">116.779</span>, <span class="fl">123.68</span>]</span>
<span id="cb7-4"><a href="#cb7-4"></a>  x <span class="op">=</span> x[..., ::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb7-5"><a href="#cb7-5"></a>  x[..., <span class="dv">0</span>] <span class="op">+=</span> mean[<span class="dv">0</span>]</span>
<span id="cb7-6"><a href="#cb7-6"></a>  x[..., <span class="dv">1</span>] <span class="op">+=</span> mean[<span class="dv">1</span>]</span>
<span id="cb7-7"><a href="#cb7-7"></a>  x[..., <span class="dv">2</span>] <span class="op">+=</span> mean[<span class="dv">2</span>]</span>
<span id="cb7-8"><a href="#cb7-8"></a>  <span class="cf">return</span> np.clip(x, <span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb7-9"><a href="#cb7-9"></a></span>
<span id="cb7-10"><a href="#cb7-10"></a>input_img_data <span class="op">=</span> np.random.random(photo.shape)</span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co"># partimos de una imagen de ruido blanco</span></span>
<span id="cb7-12"><a href="#cb7-12"></a></span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="im">import</span> time</span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="co"># iteramos</span></span>
<span id="cb7-15"><a href="#cb7-15"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb7-16"><a href="#cb7-16"></a>step <span class="op">=</span> <span class="fl">0.01</span> <span class="co"># cuanto actualizamos la imagen cada ves (learning rate)</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1500</span>):</span>
<span id="cb7-18"><a href="#cb7-18"></a>    loss_value, grads_value <span class="op">=</span> iterate([input_img_data])</span>
<span id="cb7-19"><a href="#cb7-19"></a>    input_img_data <span class="op">-=</span> grads_value <span class="op">*</span> step</span>
<span id="cb7-20"><a href="#cb7-20"></a>    <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb7-21"><a href="#cb7-21"></a>      <span class="bu">print</span>(i, loss_value)</span>
<span id="cb7-22"><a href="#cb7-22"></a></span>
<span id="cb7-23"><a href="#cb7-23"></a>total_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb7-24"><a href="#cb7-24"></a>final <span class="op">=</span> deprocess_image(input_img_data[<span class="dv">0</span>, ...])<span class="op">/</span><span class="dv">255</span></span>
<span id="cb7-25"><a href="#cb7-25"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="sc">{:02d}</span><span class="st">:</span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(<span class="bu">round</span>(total_time<span class="op">//</span><span class="dv">60</span>), total_time <span class="op">%</span> <span class="dv">60</span>))</span>
<span id="cb7-26"><a href="#cb7-26"></a>im <span class="op">=</span> Image.fromarray((final<span class="op">*</span><span class="dv">255</span>).astype(<span class="st">&#39;uint8&#39;</span>))</span>
<span id="cb7-27"><a href="#cb7-27"></a>im.save(<span class="st">&quot;/content/result.jpg&quot;</span>)</span></code></pre></div>
<p>Después de aproximadamente 10 minutos en una GPU este es el resultado</p>
<figure>
<img src="/assets/posts/style-transfer/res.jpg" alt="" /><figcaption>Resultado final (Santiago en el estilo de van Gogh)</figcaption>
</figure>
<p>Nada mal para solo unas 100 lineas de código. Ahora tu también puedes usar esta técnica para convertir tus fotos en obras de arte. Prueba modificando los parámetros del algoritmo. ¿Como se comporta si <span class="math inline">\(\lambda\)</span> disminuye? ¿Qué pasa si usas otras capas para calcular el estilo?.</p>
<p>Como vimos en este articulo las características aprendidas por redes de CNN son capaces de generalizarse para tareas de generación. Lo aprendido parce tener información util no solo para clasificar sino que capturan información de alto nivel semántico de la entrada. Esta area creo vale la pena explorar mas en profundidad.</p>
<p>Puedes descargar el código de <a href="/assets/posts/style-transfer/style_transfer.py">aquí</a>. Otras mejoras mas avanzadas podría ser usar un mejor algoritmo de optimización (agregar momentum o usar L-BFGS). También puedes experimentar agregar un regularizador como TV (<em>total variation</em>) a la función de perdida para eliminar el ruido y estimular la suavidad en la solución.</p>

        </article>

        <footer>
            <div class="footer-container">
                <div class="footer-colm">
                    <a href=http://192.168.0.27:8000>Alberto Di Biase</a>
                    <ul>
                                                    <li><a href=about.html>About</a></li>
                                                    <li><a href=categories.html>Categories</a></li>
                                            </ul>
                </div>
                <div class="footer-colm">
                    Redes Sociales:
                    <ul>
                                                    <li><a href=https://github.com/tito21/>github</a></li>
                                                    <li><a href=https://www.reddit.com/user/AlbertoDiBiase>reddit</a></li>
                                            </ul>
                </div>
                <div class="footer-colm" style="text-align: left;">
                    <p>Estudiante de Ingeniería Biomédica en la Pontificia Universidad Católica de Chile (UC). Mis pasiones son programar, los numeros y la enseñanza.</p>
                </div>
            </div>
        </footer>
        <div class="close-message">
            <p>Todo el contenido de esta pagina esta bajo la Licencia <a
            href="http://creativecommons.org/licenses/by-sa/4.0/">CC-by-sa</a> y
            el código bajo la licencia <a
            href="https://choosealicense.com/licenses/mit/">MIT</a></p>

                <p>Sitio alojado en <a href="github.com">GitHub</a> y producido
                con YASSG</p>
        </div>
    </body>

</html>