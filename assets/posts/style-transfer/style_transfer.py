# -*- coding: utf-8 -*-
"""Style Transfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNKE4KhIAGfhapLP1qF4UN0yuyjPBYn_
"""

from keras.applications import vgg19
from PIL import Image
import requests
import numpy as np
import matplotlib.pyplot as plt

# Cargamos el modelo pre entrenado
model = vgg19.VGG19(weights='imagenet', include_top=False)
print('Model loaded.')
model.summary()

# las fotos que vamos a usar
van_gogh_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/606px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg"
# van_gogh_url = "https://upload.wikimedia.org/wikipedia/commons/c/c5/Fingerprint_Arch.jpg"
santiago_url = "https://upload.wikimedia.org/wikipedia/commons/7/7e/Stog_skyline_wikipedai.jpg"
# santiago_url = "https://upload.wikimedia.org/wikipedia/commons/6/67/--%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D0%9F%D0%BE%D1%80%D1%82%D1%80%D0%B5%D1%82%D1%8B-%D0%9C%D0%B8%D1%85%D0%B0%D0%B9%D0%BB%D0%BE%D0%B2%D0%B0_%D0%95%D0%BB%D0%B5%D0%BD%D0%B0_%D0%92%D0%BB%D0%B0%D0%B4%D0%B8%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%BD%D0%B0.jpg"
van_gogh = np.array(Image.open(requests.get(van_gogh_url, stream=True).raw).convert("RGB"))
santiago = np.array(Image.open(requests.get(santiago_url, stream=True).raw).convert("RGB"))

plt.imshow(van_gogh)
plt.show()
plt.imshow(santiago)
plt.show()
print(vgg19.preprocess_input(santiago).shape)

# Necesitamos una representacion del contenido de la imagen original.
# y el estilo de la obra objetivo
from keras.models import Model
photo = vgg19.preprocess_input(np.array([santiago]))
target = vgg19.preprocess_input(np.array([van_gogh]))
target_style = []

target_content = Model(inputs=model.input, outputs=model.get_layer("block1_conv1").output).predict(photo)

target_style.append(Model(inputs=model.input, outputs=model.get_layer("block2_conv2").output).predict(target))
target_style.append(Model(inputs=model.input, outputs=model.get_layer("block2_conv1").output).predict(target))
target_style.append(Model(inputs=model.input, outputs=model.get_layer("block3_conv2").output).predict(target))
target_style.append(Model(inputs=model.input, outputs=model.get_layer("block4_conv3").output).predict(target))
target_style.append(Model(inputs=model.input, outputs=model.get_layer("block5_conv4").output).predict(target))

# print(target_content.shape)
# print(target_style.shape)

from keras import backend as K

input_img = model.inputs[0]
lam = 1e3
content = model.get_layer("block1_conv1").output
style = []
style.append(model.get_layer("block2_conv2").output)
style.append(model.get_layer("block2_conv1").output)
style.append(model.get_layer("block3_conv2").output)
style.append(model.get_layer("block4_conv3").output)
style.append(model.get_layer("block5_conv4").output)
content_loss = 0.5*K.sum(K.pow(content - target_content, 2))

def gram_matrix(x):
#   print(x.shape)
  x = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))
  return K.dot(x, K.transpose(x))

def get_style_loss(x, y, w):
  size = x.shape[1] * x.shape[2] * y.shape[1] * y.shape[2]
  target_gram = gram_matrix(y[0])
  photo_gram = gram_matrix(x[0])
  loss = 0.25*K.sum(K.pow(target_gram - photo_gram, 2))
  loss = w*loss /(3*422*750)**2
  return loss


loss = content_loss
style_loss = 0
w = 1/len(target_style)
for i, (s, ts) in enumerate(zip(style, target_style)):
  style_loss += get_style_loss(s, ts, w)


loss += lam*style_loss

grads = K.gradients(loss, input_img)[0]

# es importante normalizar los gradientes
grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)

# una funcion para calcular la los gradientes dada una imagen de entrada
iterate = K.function([input_img], [loss, grads])


def deprocess_image(x):
  # sumar la media para volver al rango original
  mean = [103.939, 116.779, 123.68]
  x = x[..., ::-1]
  x[..., 0] += mean[0]
  x[..., 1] += mean[1]
  x[..., 2] += mean[2]
  return np.clip(x, 0, 255)

input_img_data = np.random.random(photo.shape)
# input_img_data = photo
import time
# iteramos
start_time = time.time()
step = 0.01
for i in range(10000):
    loss_value, grads_value = iterate([input_img_data])
    input_img_data -= grads_value * step
    if i % 500 == 0:
      print(i, loss_value)
# print(deprocess_image(input_img_data[0, ...,]))
total_time = time.time() - start_time
final = deprocess_image(input_img_data[0, ...])/255
print("{:02d}:{:.2f}".format(round(total_time//60), total_time % 60))
plt.imshow(final)
plt.show()

plt.imsave("/content/res.jpg", final)